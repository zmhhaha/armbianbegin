# namenode.yaml
apiVersion: v1
kind: Service
metadata:
  name: hadoop-namenode
spec:
  type: NodePort  # 添加此行
  selector:
    app: hadoop-namenode
  ports:
    - port: 8020
      targetPort: 8020  # 必须与容器监听端口一致
      name: rpc
      nodePort: 30020  # 外部访问端口（范围 30000-32767）
    - port: 9870
      targetPort: 9870  # 必须与容器监听端口一致
      name: webui
      nodePort: 30870
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hadoop-namenode
spec:
  serviceName: hadoop-namenode
  replicas: 1
  selector:
    matchLabels:
      app: hadoop-namenode
  template:
    metadata:
      labels:
        app: hadoop-namenode
    spec:
      initContainers:
      - name: fix-permissions
        image: nanopct4-master:5000/fix_hadoop_permissions:latest
        securityContext:
          runAsUser: 0  # 以 root 用户运行，确保有足够权限
        command: ["sh", "-c", "chown -R 1000:1000 /hadoop/dfs/name"]
        volumeMounts:
        - name: hadoop-data
          mountPath: /hadoop/dfs/name
      containers:
      - name: namenode
#        image: apache/hadoop:3.3.6
        image: nanopct4-master:5000/hadoop_base:latest
        securityContext:
          runAsUser: 1000  # 直接指定用户 ID（如 hadoop 用户的 UID）
          runAsGroup: 1000 # 直接指定组 ID（如 hadoop 组的 GID）
        command: ["/bin/sh", "-c"]
        args:
        - |
          export HADOOP_ROLE=namenode
          /opt/hadoop/etc/hadoop/init-hadoop.sh
        volumeMounts:
        - name: hadoop-data
          mountPath: /hadoop/dfs/name
        - name: config-volume
          mountPath: /opt/hadoop/etc/hadoop/init-hadoop.sh
          subPath: init-hadoop.sh
        - name: config-volume
          mountPath: /opt/hadoop/etc/hadoop/log4j.properties
          subPath: log4j.properties
        - name: config-volume
          mountPath: /opt/hadoop/etc/hadoop/workers
          subPath: workers
        - name: config-volume
          mountPath: /opt/hadoop/etc/hadoop/core-site.xml
          subPath: core-site.xml
        - name: config-volume
          mountPath: /opt/hadoop/etc/hadoop/hdfs-site.xml
          subPath: hdfs-namenode-site.xml
        envFrom:
        - configMapRef:
            name: hadoop-env
      volumes:
      - name: config-volume
        configMap:
          name: hadoop-config
          defaultMode: 0755  # 关键权限设置
      # tolerations:
      #   - key: node-role.kubernetes.io/control-plane
      #     operator: Exists
      #     effect: NoSchedule
  volumeClaimTemplates:  # 动态生成 PVC（仅示例，CephFS 建议静态绑定）
  - metadata:
      name: hadoop-data
    spec:
      accessModes: [ "ReadWriteMany" ]
      storageClassName: ceph-fs  # CephFS 存储类
      resources:
        requests:
          storage: 50Gi